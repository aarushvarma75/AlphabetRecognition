{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "DigitRecognitionCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0kVSVcw2Njl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78HMHauRgpMY"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "A4yFSeAMgshl",
        "outputId": "8d216978-3687-43e7-fedc-a668dea7059c"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a4157efd-603d-45c9-9c7b-881ca2403cdc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a4157efd-603d-45c9-9c7b-881ca2403cdc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aarushverma\",\"key\":\"a556b53644acf230d4623a725d843ac2\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SghQoELAaSh6"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PFHQggubZND",
        "outputId": "a3abd3dc-9c76-49d4-cb7b-86d24965253c"
      },
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 82% 5.00M/6.09M [00:00<00:00, 36.4MB/s]\n",
            "100% 6.09M/6.09M [00:00<00:00, 38.9MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 55% 5.00M/9.16M [00:00<00:00, 31.0MB/s]\n",
            "100% 9.16M/9.16M [00:00<00:00, 44.8MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 71.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7dnZqwNZU3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50feed1d-fbd0-40fd-fed5-f0b52597ee1c"
      },
      "source": [
        "!mkdir train\n",
        "!unzip train.csv.zip -d train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train/train.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbvgNcAV70lp",
        "outputId": "ecae04d8-df34-4c03-f86e-a7853abb5255"
      },
      "source": [
        "!mkdir test\n",
        "!unzip test.csv.zip -d test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.csv.zip\n",
            "  inflating: test/test.csv           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N55kY0ANco2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d668a9-abb1-40d1-849e-0af55efa88d2"
      },
      "source": [
        "!mkdir images\n",
        "!mkdir test_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘test_images’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrjVxA_ciWen",
        "outputId": "219dce4b-b098-4bcc-c409-f3e64f3506f3"
      },
      "source": [
        "import csv                   #For train images\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import os\n",
        " \n",
        "csv_File_Path = '/content/train/train.csv'# Downloded csv file path\n",
        " \n",
        "count = 1\n",
        "last_digit_Name =  None\n",
        " \n",
        "image_Folder_Path = '/content/images'# Target folder path\n",
        " \n",
        "Alphabet_Mapping_List = list(['0','1','2','3','4','5','6','7','8','9'])\n",
        " \n",
        "for alphabet in Alphabet_Mapping_List:\n",
        "    path = image_Folder_Path + '/' + alphabet\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "df = pd.read_csv(csv_File_Path)\n",
        "for i in range(len(df)):\n",
        "    digit_Name = df.loc[i][0]\n",
        "    image_array = np.array(df.loc[i][1:])\n",
        "    image_array = image_array.reshape(28, 28)\n",
        "    new_image = Image.fromarray(image_array.astype('uint8'))\n",
        "    \n",
        "    image_Path = image_Folder_Path + '/' + str(digit_Name) + '/' + str(digit_Name) + '-' + str(count) + '.png'\n",
        "    new_image.save(image_Path)\n",
        "    count = count + 1\n",
        "\n",
        "    if count % 1000 == 0:\n",
        "        print (\"Images processed: \" + str(count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images processed: 1000\n",
            "Images processed: 2000\n",
            "Images processed: 3000\n",
            "Images processed: 4000\n",
            "Images processed: 5000\n",
            "Images processed: 6000\n",
            "Images processed: 7000\n",
            "Images processed: 8000\n",
            "Images processed: 9000\n",
            "Images processed: 10000\n",
            "Images processed: 11000\n",
            "Images processed: 12000\n",
            "Images processed: 13000\n",
            "Images processed: 14000\n",
            "Images processed: 15000\n",
            "Images processed: 16000\n",
            "Images processed: 17000\n",
            "Images processed: 18000\n",
            "Images processed: 19000\n",
            "Images processed: 20000\n",
            "Images processed: 21000\n",
            "Images processed: 22000\n",
            "Images processed: 23000\n",
            "Images processed: 24000\n",
            "Images processed: 25000\n",
            "Images processed: 26000\n",
            "Images processed: 27000\n",
            "Images processed: 28000\n",
            "Images processed: 29000\n",
            "Images processed: 30000\n",
            "Images processed: 31000\n",
            "Images processed: 32000\n",
            "Images processed: 33000\n",
            "Images processed: 34000\n",
            "Images processed: 35000\n",
            "Images processed: 36000\n",
            "Images processed: 37000\n",
            "Images processed: 38000\n",
            "Images processed: 39000\n",
            "Images processed: 40000\n",
            "Images processed: 41000\n",
            "Images processed: 42000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okgEVGaX8Vjm",
        "outputId": "91c8354a-ee16-4010-e1ce-7bfdde61e013"
      },
      "source": [
        "import csv                   #For Test Images\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import os\n",
        " \n",
        "csv_File_Path = '/content/test/test.csv'# Downloded csv file path\n",
        " \n",
        "count = 1\n",
        "last_digit_Name =  None\n",
        " \n",
        "image_Folder_Path = '/content/test_images'# Target folder path\n",
        "os.makedirs(image_Folder_Path + '/test_set')\n",
        "df = pd.read_csv(csv_File_Path)\n",
        "for i in range(len(df)):\n",
        "    image_array = np.array(df.loc[i])\n",
        "    image_array = image_array.reshape(28, 28)\n",
        "    new_image = Image.fromarray(image_array.astype('uint8'))\n",
        "    \n",
        "    image_Path = image_Folder_Path + '/test_set/' + str(count) + '.png'\n",
        "    new_image.save(image_Path)\n",
        "    count = count + 1\n",
        "\n",
        "    if count % 1000 == 0:\n",
        "        print (\"Images processed: \" + str(count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images processed: 1000\n",
            "Images processed: 2000\n",
            "Images processed: 3000\n",
            "Images processed: 4000\n",
            "Images processed: 5000\n",
            "Images processed: 6000\n",
            "Images processed: 7000\n",
            "Images processed: 8000\n",
            "Images processed: 9000\n",
            "Images processed: 10000\n",
            "Images processed: 11000\n",
            "Images processed: 12000\n",
            "Images processed: 13000\n",
            "Images processed: 14000\n",
            "Images processed: 15000\n",
            "Images processed: 16000\n",
            "Images processed: 17000\n",
            "Images processed: 18000\n",
            "Images processed: 19000\n",
            "Images processed: 20000\n",
            "Images processed: 21000\n",
            "Images processed: 22000\n",
            "Images processed: 23000\n",
            "Images processed: 24000\n",
            "Images processed: 25000\n",
            "Images processed: 26000\n",
            "Images processed: 27000\n",
            "Images processed: 28000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZejO4n-82Njt"
      },
      "source": [
        "batch_size = 32\n",
        "image_height = 28\n",
        "image_width = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw4-lH6f2Njt",
        "outputId": "252a0ae5-6b5e-48df-e5de-c8265b2d5b88"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/images', \n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size = (image_height, image_width),\n",
        "    batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 42000 files belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWoA09MZ2Nju",
        "outputId": "caaf488c-5c26-4fa6-bad4-decbef0b93ef"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/test_images', \n",
        "    labels='inferred',\n",
        "    shuffle = False,\n",
        "    label_mode='categorical',\n",
        "    image_size = (image_height, image_width),\n",
        "    batch_size = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28000 files belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "HZo-2I3d2Njv",
        "outputId": "5d15d872-cf2a-453b-e04d-0dfe4519a769"
      },
      "source": [
        "for image,label in val_ds.take(2):\n",
        "    plt.imshow(image[0]/255)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtGaAI_u2Njw"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "num_classes = 10\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "    layers.Conv2D(32,3, activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2wLLf02Njx"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.losses.CategoricalCrossentropy(from_logits = True),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBRW8chw2Njx",
        "outputId": "9f7ecc79-44fa-4169-be1d-e9e8b437cb14"
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1313/1313 [==============================] - 47s 36ms/step - loss: 0.1042 - accuracy: 0.9681\n",
            "Epoch 2/10\n",
            "1313/1313 [==============================] - 47s 36ms/step - loss: 0.0459 - accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "1313/1313 [==============================] - 47s 36ms/step - loss: 0.0325 - accuracy: 0.9899\n",
            "Epoch 4/10\n",
            "1313/1313 [==============================] - 47s 36ms/step - loss: 0.0234 - accuracy: 0.9925\n",
            "Epoch 5/10\n",
            "1313/1313 [==============================] - 46s 35ms/step - loss: 0.0175 - accuracy: 0.9944\n",
            "Epoch 6/10\n",
            "1313/1313 [==============================] - 46s 35ms/step - loss: 0.0141 - accuracy: 0.9954\n",
            "Epoch 7/10\n",
            "1313/1313 [==============================] - 47s 35ms/step - loss: 0.0113 - accuracy: 0.9964\n",
            "Epoch 8/10\n",
            "1313/1313 [==============================] - 47s 35ms/step - loss: 0.0092 - accuracy: 0.9967\n",
            "Epoch 9/10\n",
            "1313/1313 [==============================] - 47s 35ms/step - loss: 0.0086 - accuracy: 0.9971\n",
            "Epoch 10/10\n",
            "1313/1313 [==============================] - 47s 35ms/step - loss: 0.0092 - accuracy: 0.9969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68870520d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "4yTk1_APo4a7",
        "outputId": "daddb93f-9552-4703-de10-303497344bb0"
      },
      "source": [
        "for image, labels in train_ds.take(1):\n",
        "  i = 5\n",
        "  pred = model.predict_classes(image)\n",
        "  plt.imshow(image[i]/255)\n",
        "  print(pred[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOB0lEQVR4nO3df4hd9ZnH8c9HN2qIRZMNG2KqphYhyIoaY1hQFpdSyaqQSKHUPxZ/DKRgIxVWNMYfDepC2N3uggrVKQ3NqpsimrShyFqVsq5/KBlFTWJsjTGhhpjoBmyKgerk2T/mZJnEOd87uefcuTd53i8Y5t7zzD3n8eIn59zzPfd8HRECcPI7pd8NAJgahB1IgrADSRB2IAnCDiTxF1O5Mduc+gd6LCI80fJGe3bbS2z/zvYO2yubrAtAb7nbcXbbp0r6vaRvS/pI0mZJN0bEu4XXsGcHeqwXe/bFknZExM6I+LOkX0ha2mB9AHqoSdjnSfrDuOcfVcuOYnu57RHbIw22BaChnp+gi4hhScMSh/FAPzXZs++RdO6451+vlgEYQE3CvlnShba/Yfs0Sd+TtKmdtgC0revD+Ij40vYKSS9IOlXS2ojY1lpnAFrV9dBbVxvjMzvQcz25qAbAiYOwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSmdMpm4HjMnDmzWF+1alWxfuedd9bWNm0qT3Gwffv2Yv3JJ58s1t97771ifXR0tFjvBfbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEs7iikenTpxfr8+bNq60NDQ0VX3v77bc32nY/PfPMM8V66RqAPXv2NNp23SyujS6qsb1L0kFJo5K+jIhFTdYHoHfauILu7yLi0xbWA6CH+MwOJNE07CHpN7bfsL18oj+wvdz2iO2RhtsC0EDTw/irImKP7b+S9KLt9yLilfF/EBHDkoYlTtAB/dRozx4Re6rf+yVtlLS4jaYAtK/rsNueYftrRx5LukbS1rYaA9CuJofxcyRttH1kPf8ZEf/VSlcYGJ3Gsh955JFi/dZbb22znRPGggULivW5c+fW1pqOs9fpOuwRsVPSJS32AqCHGHoDkiDsQBKEHUiCsANJEHYgCW4lndzpp59erD/66KPF+i233NJmO8dlx44dxfoTTzxRWzvttNOKr3399de76umI1157rVg/dOhQo/V3gz07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPtJbtq0acX6yEj5bmEXXXRRm+0cl/vuu69YX7t2bbG+b9++Nts54bFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGc/CVx88cW1tZUrVxZf2+tx9F27dtXWvvOd7xRfu2XLlmJ9dHS0m5bSYs8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzn4CuOSS8mS5Dz30UG3tuuuua7udo5TG0SXpmmuuqa198MEHLXeDko57dttrbe+3vXXcslm2X7T9fvV7Zm/bBNDUZA7jfy5pyTHLVkp6OSIulPRy9RzAAOsY9oh4RdKBYxYvlbSuerxO0rKW+wLQsm4/s8+JiL3V448lzan7Q9vLJS3vcjsAWtL4BF1EhO0o1IclDUtS6e8A9Fa3Q2/7bM+VpOr3/vZaAtAL3YZ9k6Sbqsc3SfpVO+0A6BVHlI+sba+XdLWk2ZL2SfqRpF9KekbSeZJ2S/puRBx7Em+idXEYP4HLL7+8WH/++eeL9dmzZ7fZzlHWr19frD/wwAPF+s6dO9tsB5MQEZ5oecfP7BFxY03pW406AjCluFwWSIKwA0kQdiAJwg4kQdiBJDoOvbW6saRDbxdccEGx/uqrrxbrc+bUXo3cWKehsSVLjv0O1NH4murgqRt6Y88OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwK+kWTJ8+vVi/5557ivVejqMfPny4WL///vuLdcbRTx7s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCb7P3oLVq1cX653Gsvvpiy++KNY3b95crG/YsKFYX7duXW3twIGOdx9HF/g+O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7C4aHh4v1oaGhnm7/3nvvra0tW7as+Norrrii7XaOsnv37tpapzH8m2++uVg/dOhQNy2d9LoeZ7e91vZ+21vHLVtte4/tt6qfa9tsFkD7JnMY/3NJE00L8u8RcWn183y7bQFoW8ewR8QrkriuETjBNTlBt8L2O9Vh/sy6P7K93PaI7ZEG2wLQULdh/4mkb0q6VNJeST+u+8OIGI6IRRGxqMttAWhBV2GPiH0RMRoRhyX9VNLidtsC0Lauwm577rinN0jaWve3AAZDx/vG214v6WpJs21/JOlHkq62famkkLRL0vd72GN6Tz31VLH++OOP19Yee+yx4mtnzJjRVU9HrFixolhftWpVbe38888vvrZTb0uXLi3WR0dHi/VsOoY9Im6cYPHPetALgB7iclkgCcIOJEHYgSQIO5AEYQeS4Cuuk1S6XXTpK6aSdMopzf5NXbhwYbH+9ttvN1p/E53+2x588MHa2t13391o3S+88EKxXhqa63QL7RMZt5IGkiPsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ5+kWbNm1dY++eSTnm57kMfZm9i2bVuxvmDBgkbrL13/sGbNmkbrHmSMswPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEh3vLosxpdsSHzhQngqvNEZ/sjvrrLNqa2eccUZPt33DDTfU1k7mcfY67NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2Sfps88+q61t3Lix+NqhoaFG2z7vvPOK9X5+n/3ss88u1tetW1dbmz9/fsvdHO3zzz/v6fpPNB337LbPtf1b2+/a3mb7h9XyWbZftP1+9Xtm79sF0K3JHMZ/KekfI+IiSX8j6Qe2L5K0UtLLEXGhpJer5wAGVMewR8TeiHizenxQ0nZJ8yQtlXTkGG2dpGW9ahJAc8f1md32fEmXSXpd0pyI2FuVPpY0p+Y1yyUt775FAG2Y9Nl422dKek7SHRHxx/G1GLtr5YQ3k4yI4YhYFBGLGnUKoJFJhd32NI0F/emI2FAt3md7blWfK2l/b1oE0IaOt5K2bY19Jj8QEXeMW/4vkv43ItbYXilpVkTc1WFdJ+ytpEsuu+yyYn3Tpk3F+jnnnFOsd/oK7V131b/tBw8eLL52xowZxfptt91WrJ955pnFetPbQZccOnSoWL/yyitrayfq7bcno+5W0pP5zH6lpH+QtMX2W9WyVZLWSHrG9pCk3ZK+20ajAHqjY9gj4lVJE/5LIelb7bYDoFe4XBZIgrADSRB2IAnCDiRB2IEkmLJ5CnQah3/44YeL9SVLlrTZzsB49tlni/WXXnqpUf3DDz887p5OBkzZDCRH2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+AKZNm1asL168uFi//vrra2unnFL+93zhwoXF+sjISLHeydNPP11b2759e/G1pWmyUY9xdiA5wg4kQdiBJAg7kARhB5Ig7EAShB1IgnF24CTDODuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJNEx7LbPtf1b2+/a3mb7h9Xy1bb32H6r+rm29+0C6FbHi2psz5U0NyLetP01SW9IWqax+dj/FBH/OumNcVEN0HN1F9VMZn72vZL2Vo8P2t4uaV677QHoteP6zG57vqTLJL1eLVph+x3ba23PrHnNctsjtpvd3whAI5O+Nt72mZL+W9I/RcQG23MkfSopJD2ksUP9Wzusg8N4oMfqDuMnFXbb0yT9WtILEfFvE9TnS/p1RPx1h/UQdqDHuv4ijG1L+pmk7eODXp24O+IGSVubNgmgdyZzNv4qSf8jaYukw9XiVZJulHSpxg7jd0n6fnUyr7Qu9uxAjzU6jG8LYQd6j++zA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuh4w8mWfSpp97jns6tlg2hQexvUviR661abvZ1fV5jS77N/ZeP2SEQs6lsDBYPa26D2JdFbt6aqNw7jgSQIO5BEv8M+3Oftlwxqb4Pal0Rv3ZqS3vr6mR3A1On3nh3AFCHsQBJ9CbvtJbZ/Z3uH7ZX96KGO7V22t1TTUPd1frpqDr39treOWzbL9ou2369+TzjHXp96G4hpvAvTjPf1vev39OdT/pnd9qmSfi/p25I+krRZ0o0R8e6UNlLD9i5JiyKi7xdg2P5bSX+S9B9Hptay/c+SDkTEmuofypkRcfeA9LZaxzmNd496q5tm/Gb18b1rc/rzbvRjz75Y0o6I2BkRf5b0C0lL+9DHwIuIVyQdOGbxUknrqsfrNPY/y5Sr6W0gRMTeiHizenxQ0pFpxvv63hX6mhL9CPs8SX8Y9/wjDdZ87yHpN7bfsL28381MYM64abY+ljSnn81MoOM03lPpmGnGB+a962b686Y4QfdVV0XEQkl/L+kH1eHqQIqxz2CDNHb6E0nf1NgcgHsl/bifzVTTjD8n6Y6I+OP4Wj/fuwn6mpL3rR9h3yPp3HHPv14tGwgRsaf6vV/SRo197Bgk+47MoFv93t/nfv5fROyLiNGIOCzpp+rje1dNM/6cpKcjYkO1uO/v3UR9TdX71o+wb5Z0oe1v2D5N0vckbepDH19he0Z14kS2Z0i6RoM3FfUmSTdVj2+S9Ks+9nKUQZnGu26acfX5vev79OcRMeU/kq7V2Bn5DyTd248eavq6QNLb1c+2fvcmab3GDuu+0Ni5jSFJfynpZUnvS3pJ0qwB6u1JjU3t/Y7GgjW3T71dpbFD9HckvVX9XNvv967Q15S8b1wuCyTBCTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSOL/AH2BgjU7AWz5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjlTV0L9kXvq"
      },
      "source": [
        "**For Submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo9kU-r-BqMD",
        "outputId": "715f7f24-ffcd-491c-8f1b-ff451c28326d"
      },
      "source": [
        "import csv                       # 0.98725 accuracy on MNIST data\n",
        "row_list = [['ImageId', 'Label']]\n",
        "new_row_list = [['ImageId', 'Label']]\n",
        "cnt = 0\n",
        "dirFiles = os.listdir('/content/test_images/test_set')\n",
        "dirFiles.sort() \n",
        "for image, labels in val_ds:\n",
        "  pred = model.predict_classes(image)\n",
        "  temp = [dirFiles[cnt][:-4], pred[0]]\n",
        "  row_list.append(temp)\n",
        "  cnt = cnt+1\n",
        "for i in range(1,len(row_list)):\n",
        "  for j in row_list:\n",
        "    if(str(i) == j[0]):\n",
        "      ele = [str(i),j[1]]\n",
        "      new_row_list.append(ele)\n",
        "      break;\n",
        "with open('submission.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(new_row_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wksLj3faWXvw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}